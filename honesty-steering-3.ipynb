{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cma1114/enhanced_hooking.git\n",
      "  Cloning https://github.com/cma1114/enhanced_hooking.git to /tmp/pip-req-build-x_djclr3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/cma1114/enhanced_hooking.git /tmp/pip-req-build-x_djclr3\n",
      "  Resolved https://github.com/cma1114/enhanced_hooking.git to commit 3c751e776d3f3a4a0fcbc0aea35556285d0d4c35\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torch>=2.2.0 (from enhanced-hooking==0.1)\n",
      "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->enhanced-hooking==0.1) (3.9.0)\n",
      "Collecting typing-extensions>=4.8.0 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->enhanced-hooking==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->enhanced-hooking==0.1) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->enhanced-hooking==0.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.2.0->enhanced-hooking==0.1) (2023.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.1 (from torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.2.0->enhanced-hooking==0.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.2.0->enhanced-hooking==0.1) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.2.0->enhanced-hooking==0.1) (1.3.0)\n",
      "Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m179.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m153.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m145.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m164.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: enhanced-hooking\n",
      "  Building wheel for enhanced-hooking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for enhanced-hooking: filename=enhanced_hooking-0.1-py3-none-any.whl size=4475 sha256=8f80b6d5a09c7173952c03614f300f5d8234cd2f86ebacc2f0360d475fd57c77\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-k3ohjgli/wheels/82/ed/86/16599a39b92e6aa7a76f7cb3f37cf00dcd6f8e1c8844e23bcc\n",
      "Successfully built enhanced-hooking\n",
      "Installing collected packages: typing-extensions, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, enhanced-hooking\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.3.1 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed enhanced-hooking-0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 triton-2.3.1 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/cma1114/enhanced_hooking.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.3.1 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U torch transformers matplotlib pandas scikit-learn seaborn datasets\n",
    "\n",
    "import torch \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from enhanced_hooking import get_activations, add_activations_and_generate, clear_hooks, get_activations_and_generate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8450715c5d040e9a8eb93dc986a78d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9854280ffaaf4de89e2d342e8b02ccf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b6182a16db408e960ee389cd9392f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632345cc2113444284944d3ef05adb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3afd951d8c1439fba65701a3eb3bbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791bc3a3819d47549fe2232485c6a11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69eaa0602f4e459ea3443101094a18ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3bbc215ebd43958f16a09b468c3a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a7be6927644f1bb4bf257d5dae287f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0b6600e1624101b707b4a1af3d1cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b9b42a1d3b4bef8c5627aed0d6257b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "HF_TOKEN='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'\n",
    "def load_model(model_path, device, center_weights=True):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, token=HF_TOKEN).to(device)\n",
    "    if center_weights:\n",
    "        for name, param in model.named_parameters():\n",
    "            if '.'.join(name.split('.')[-2:]) in ['wte.weight','wpe.weight','c_proj.weight','c_proj.bias']:\n",
    "                param.data -= param.data.mean()\n",
    "                print(name, param.data.mean(), param.size())\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, token=HF_TOKEN)\n",
    "    model.tokenizer = tokenizer\n",
    "    model.tokenizer.padding_side = \"left\" #for batching; right (default in gpt2) for training, left for generation\n",
    "    model.tokenizer.pad_token_id = model.tokenizer.eos_token_id \n",
    "    return model\n",
    "\n",
    "\n",
    "model=None\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "_ = torch.set_grad_enabled(False)\n",
    "model_path: str = \"meta-llama/Llama-2-13b-chat-hf\"#\"meta-llama/Llama-2-13b-chat-hf\" #even on an A40 I have to load 13b in half precision\n",
    "device: str =  \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "center_weights=False\n",
    "\n",
    "model = load_model(model_path, device, center_weights=center_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"data/\"\n",
    "user_tag, asst_tag = \"[INST] \", \" [/INST]\"\n",
    "sys_tag_open, sys_tag_closed = \"<<SYS>> \", \" <</SYS>>\"\n",
    "model_numlayers = model.config.n_layer\n",
    "\n",
    "strip_quotes = lambda s: s[1:-1] if len(s) > 1 and (s.startswith('\"') and s.endswith('\"') or s.startswith(\"'\") and s.endswith(\"'\")) else s\n",
    "\n",
    "pos_persona = \"Pretend that you are always honest, no matter what.\"\n",
    "neg_persona = \"Pretend that you are dishonest when it serves you.\"\n",
    "pos_label = \"(A)\"\n",
    "neg_label = \"(B)\"\n",
    "key_token_offset=1\n",
    "pair_statements = False\n",
    "\n",
    "df = pd.read_csv(datadir+\"facts_true_false.csv\")\n",
    "true_statements = df[df['label'] == 1]['statement'].values.tolist()\n",
    "false_statements = df[df['label'] == 0]['statement'].values.tolist()\n",
    "\n",
    "def template(persona: str, stmt: str, label: str) -> str:\n",
    "    return f\"{user_tag}{sys_tag_open}{persona}{sys_tag_closed} Question: Is the following claim true or false? \\\"{strip_quotes(stmt)}\\\"\\n\\nChoices:\\n (A) True\\n (B) False\\n\\nAnswer:{asst_tag} {label}\"\n",
    "\n",
    "dataset = []\n",
    "if pair_statements:\n",
    "    for truth in true_statements:\n",
    "        dataset.append((template(pos_persona, truth, pos_label), template(neg_persona, truth, neg_label)))\n",
    "    for lie in false_statements:\n",
    "        dataset.append((template(pos_persona, lie, neg_label), template(neg_persona, lie, pos_label)))\n",
    "\n",
    "    letters_pos = np.array([\"T\" for _ in range(len(dataset)//2)] + [\"F\" for _ in range(len(dataset)//2)])\n",
    "    letters_neg = np.array([\"F\" for _ in range(len(dataset)//2)] + [\"T\" for _ in range(len(dataset)//2)])\n",
    "else:\n",
    "    for i, (truth, lie) in enumerate(zip(true_statements, false_statements)):\n",
    "        dataset.append((template(pos_persona, truth, pos_label), template(neg_persona, lie, pos_label)))\n",
    "    for i, (truth, lie) in enumerate(zip(true_statements, false_statements)):\n",
    "        dataset.append((template(pos_persona, lie, neg_label), template(neg_persona, truth, neg_label)))\n",
    "\n",
    "    letters_pos = np.array([\"T\" for _ in range(len(dataset)//2)] + [\"F\" for _ in range(len(dataset)//2)])\n",
    "    letters_neg = np.array([\"F\" for _ in range(len(dataset)//2)] + [\"T\" for _ in range(len(dataset)//2)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepend_bos = False\n",
    "steering_type = \"Continous\"\n",
    "AGG_TYPE = \"PCA\"\n",
    "normvec = False\n",
    "sampling_kwargs = {\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id,\n",
    "                    \"max_new_tokens\": 60\n",
    "                    , \"temperature\": 0.5\n",
    "                   , \"top_p\": 0.3\n",
    "                  , \"do_sample\": False #True\n",
    "                  , \"repetition_penalty\": 1.1 #2.0\n",
    "                   ,\"penalty_alpha\": 0.6 \n",
    "                   ,\"top_k\": 4\n",
    "                    }\n",
    "outputdir=\"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenizer.padding_side = \"left\"#\"right\"\n",
    "layers = range(model_numlayers)\n",
    "\n",
    "accumulated_activations_pos = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "accumulated_activations_neg = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "accumulated_activations_diff = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "\n",
    "batch_size = 32\n",
    "batched_dataset = [\n",
    "    (\n",
    "        [pair[0] for pair in dataset[i:i+batch_size]],\n",
    "        [pair[1] for pair in dataset[i:i+batch_size]]\n",
    "    )\n",
    "    for i in range(0, len(dataset), batch_size)\n",
    "]\n",
    "\n",
    "for batch_pos, batch_neg in tqdm(batched_dataset, desc='Processing behavioral prompts'):\n",
    "    encoded_pos = model.tokenizer.encode(batch_pos, return_tensors=\"pt\", padding=True)\n",
    "    encoded_neg = model.tokenizer.encode(batch_neg, return_tensors=\"pt\", padding=True)\n",
    "    batch_tokens_pos = encoded_pos['input_ids']\n",
    "    batch_tokens_neg = encoded_neg['input_ids']\n",
    "    last_token_positions_pos = (encoded_pos['attention_mask'].sum(dim=1) - key_token_offset).tolist()\n",
    "    last_token_positions_neg = (encoded_neg['attention_mask'].sum(dim=1) - key_token_offset).tolist()\n",
    "\n",
    "    get_at = add_at = \"end\"\n",
    "\n",
    "    layer_positions = {}\n",
    "    for layer in layers:\n",
    "        layer_positions[layer] = [[pos for pos in last_token_positions_pos]]\n",
    "    \n",
    "    activations = get_activations(model, batch_tokens_pos, layer_positions, get_at=get_at)\n",
    "    for layer, position in activations.items():\n",
    "        for pos, tensor in position.items():\n",
    "            accumulated_activations_diff[layer][pos] = torch.cat([accumulated_activations_diff[layer][pos], tensor.clone()], dim=0)\n",
    "            accumulated_activations_pos[layer][pos] = torch.cat([accumulated_activations_pos[layer][pos], tensor], dim=0)\n",
    "\n",
    "    if len(batch_neg[0]) > 1:\n",
    "        layer_positions = {}\n",
    "        for layer in layers:\n",
    "            layer_positions[layer] = [[pos for pos in last_token_positions_neg]]\n",
    "        activations = get_activations(model, batch_tokens_neg, layer_positions, get_at=get_at)\n",
    "        for layer, position in activations.items():\n",
    "            for pos, tensor in position.items():\n",
    "                accumulated_activations_neg[layer][pos] = torch.cat([accumulated_activations_diff[layer][pos], tensor.clone()], dim=0)\n",
    "                accumulated_activations_diff[layer][pos][-len(batch_pos):] -= tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sign(activation_pos, activation_neg, direction):\n",
    "    projections_pos = (activation_pos @ direction) / torch.norm(direction)\n",
    "    projections_neg = (activation_neg @ direction) / torch.norm(direction)\n",
    "\n",
    "    positive_smaller_mean = np.mean(\n",
    "        [projections_pos[i] < projections_neg[i] for i in range(len(projections_pos))]\n",
    "    )\n",
    "    positive_larger_mean = np.mean(\n",
    "        [projections_pos[i] > projections_neg[i] for i in range(len(projections_pos))]\n",
    "    )\n",
    "    return -1 if positive_smaller_mean > positive_larger_mean else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_really_raw_pca = True\n",
    "use_lesser_raw_pca = False\n",
    "use_raw = False\n",
    "steering_vectors = {} \n",
    "enhanced_hook_activation_to_add = {} \n",
    "if use_really_raw_pca:\n",
    "    for layer, positions in accumulated_activations_diff.items():\n",
    "        embeds = []\n",
    "        for pos in range(len(positions)):\n",
    "            train = positions[pos] - positions[pos].mean(axis=0, keepdims=True)\n",
    "            pca_model = PCA(n_components=2, whiten=False).fit(train)\n",
    "            embeds.append(torch.from_numpy(pca_model.components_[1].astype(np.float32)).squeeze(0))\n",
    "        enhanced_hook_activation_to_add[layer] = torch.stack(embeds)\n",
    "elif use_raw:\n",
    "    steering_vectors = {} \n",
    "    for layer, positions in accumulated_activations_pos.items():\n",
    "        embeds = []\n",
    "        for pos in range(len(position)):\n",
    "            activations_pos = accumulated_activations_pos[layer][pos]\n",
    "            activations_neg = accumulated_activations_neg[layer][pos]\n",
    "\n",
    "            activations = torch.cat([activations_pos, activations_neg], dim=0)\n",
    "            pca_model = PCA(n_components=2)\n",
    "            projected_activations = pca_model.fit_transform(activations)\n",
    "            coef1, coef2 = 0, 1#pca_model.explained_variance_[0],pca_model.explained_variance_[1]\n",
    "            embeds.append(torch.from_numpy(pca_model.components_[0].astype(np.float32))*coef1/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[0].astype(np.float32))))\n",
    "            embeds[-1]+= torch.from_numpy(pca_model.components_[1].astype(np.float32))*coef2/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[1].astype(np.float32)))\n",
    "        steering_vectors[layer] = torch.stack(embeds)\n",
    "elif use_lesser_raw_pca:\n",
    "    for layer, positions in accumulated_activations_diff.items():#dictionary where keys are layers and values are dicts where keys are positions and values are len(dataset) d-embed tensors\n",
    "        embeds = []\n",
    "        for pos in range(len(positions)):\n",
    "            train = positions[pos] - positions[pos].mean(axis=0, keepdims=True)\n",
    "            pca_model = PCA(n_components=2, whiten=False).fit(train)\n",
    "            coef1, coef2 = 0,1#pca_model.explained_variance_[0],pca_model.explained_variance_[1]\n",
    "            embeds.append(torch.from_numpy(pca_model.components_[0].astype(np.float32))*coef1/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[0].astype(np.float32))))\n",
    "            embeds[-1]+=torch.from_numpy(pca_model.components_[1].astype(np.float32))*coef2/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[1].astype(np.float32)))\n",
    "        steering_vectors[layer] = torch.stack(embeds)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meandiff = {}\n",
    "for layer, position in accumulated_activations_diff.items():\n",
    "    meandiff[layer] = []\n",
    "    for pos in range(len(position)):\n",
    "        meandiff[layer].append(torch.mean(accumulated_activations_diff[layer][pos].clone(), dim=0))\n",
    "normmeandiff = {}\n",
    "for layer, position in meandiff.items():\n",
    "    normmeandiff[layer] = []\n",
    "    for pos in range(len(position)):\n",
    "        normmeandiff[layer].append(meandiff[layer][pos] / torch.norm(meandiff[layer][pos], p=2, dim=0, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "ofname = 'directions_llama2_7b_f16_persona_lasttoken_pc2raw.pkl'\n",
    "with open(outputdir+ofname, 'wb') as f:\n",
    "    pickle.dump(steering_vectors, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position=0\n",
    "results = {layer: {} for layer in layers}\n",
    "\n",
    "for layer in layers:\n",
    "    mult = 1\n",
    "\n",
    "    sims_pos = (accumulated_activations_pos[layer][position] @ (enhanced_hook_activation_to_add[layer][position] * mult) / torch.norm(enhanced_hook_activation_to_add[layer][position]))\n",
    "    sims_neg = (accumulated_activations_neg[layer][position] @ (enhanced_hook_activation_to_add[layer][position] * mult) / torch.norm(enhanced_hook_activation_to_add[layer][position]))\n",
    "    # sims_pos = (accumulated_activations_pos[layer][position] @ (meandiffs[layer][position] * mult)) / torch.norm(meandiffs[layer][position])\n",
    "    # sims_neg = (accumulated_activations_neg[layer][position] @ (meandiffs[layer][position] * mult)) / torch.norm(meandiffs[layer][position])\n",
    "\n",
    "    H_test = [[sims_pos[i], sims_neg[i]] for i in range(0, len(sims_neg))]\n",
    "    cors = np.mean([max(H) == H[0] for H in H_test])\n",
    "\n",
    "    results[layer] = cors\n",
    "\n",
    "plt.plot(layers, [results[layer] for layer in layers], marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proejection_honest = {}\n",
    "proejection_dishonest = {}\n",
    "\n",
    "for layer in layers:\n",
    "    mult = 1\n",
    "    centered_pos = accumulated_activations_pos[layer][position] - torch.mean(accumulated_activations_pos[layer][position], dim=0, keepsdim=True)\n",
    "    centered_neg = accumulated_activations_neg[layer][position] - torch.mean(accumulated_activations_neg[layer][position], dim=0, keepsdim=True)\n",
    "\n",
    "    proejection_honest[layer] = centered_pos.matmult(enhanced_hook_activation_to_add[layer][position]*mult) / (torch.norm(enhanced_hook_activation_to_add[layer][position]) * torch.norm(centered_pos, dim=1, keepdim=True))\n",
    "    proejection_dishonest[layer] = centered_neg.matmult(enhanced_hook_activation_to_add[layer][position]*mult) / (torch.norm(enhanced_hook_activation_to_add[layer][position]) * torch.norm(centered_neg, dim=1, keepdim=True))\n",
    "\n",
    "projection_honest_means = [torch.mean(proejection_honest[layer]).item() for layer in layers]\n",
    "projection_dishonest_means = [torch.mean(proejection_dishonest[layer]).item() for layer in layers]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(layers, projection_honest_means, label=\"Honest\", marker=\"o\")\n",
    "plt.plot(layers, projection_dishonest_means, label=\"Honest\", marker=\"o\")\n",
    "plt.xlabel('layer')\n",
    "plt.ylabel('Mean Projections onto the \"honest\" direction')\n",
    "plt.title('Mean Projections of Inputs onto \"Honest\" Direction Across Layers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_honest = {}\n",
    "cosine_dishonest = {}\n",
    "\n",
    "for layer in layers:\n",
    "    mult = 1\n",
    "    centered_pos = accumulated_activations_pos[layer][position] - torch.mean(accumulated_activations_pos[layer][position], dim=0, keepsdim=True)\n",
    "    centered_neg = accumulated_activations_neg[layer][position] - torch.mean(accumulated_activations_neg[layer][position], dim=0, keepsdim=True)\n",
    "\n",
    "    direction_pos = enhanced_hook_activation_to_add[layer][position] * mult\n",
    "    direction_neg = enhanced_hook_activation_to_add[layer][position] * mult\n",
    "\n",
    "    cosine_honest[layer] = torch.sum(centered_pos * direction_pos, dim=1) / (torch.norm(centered_pos, dim=1) * torch.norm(direction_pos))\n",
    "    cosine_dishonest[layer] = torch.sum(centered_pos * direction_neg, dim=1) / (torch.norm(centered_neg, dim=1) * torch.norm(direction_neg))\n",
    "cosine_honest_means = [torch.median(cosine_honest[layer]).item() for layer in layers]\n",
    "cosine_dishonest_means = [torch.mean(cosine_dishonest[layer]).item() for layer in layers]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(layers, projection_honest_means, label=\"Honest\", marker=\"o\")\n",
    "plt.plot(layers, projection_dishonest_means, label=\"Honest\", marker=\"o\")\n",
    "plt.xlabel('layer')\n",
    "plt.ylabel('Mean Cosine Similarity onto the \"honest\" direction')\n",
    "plt.title('Mean Cosine Similarity of Inputs onto \"Honest\" Direction Across Layers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1 = \"T\"\n",
    "ans2 = \"F\"\n",
    "def plot_projection(activations_pos, activations_neg, pc, ax, title, type):\n",
    "    if type != \"both\":\n",
    "        lbl = type.split(\"_\")[1]\n",
    "        activation_pos_projected = np.dot(activations_pos, pc)\n",
    "        activation_neg_projected = np.dot(activations_neg, pc)\n",
    "        ax.hist(activation_pos_projected, bins=50, alpha=0.5, label=\"+\"+lbl)\n",
    "        ax.hist(activation_neg_projected, bins=50, alpha=0.5, label=\"-\"+lbl)\n",
    "        ax.legend()\n",
    "    else:\n",
    "        activation_pos_projected = np.dot(activations_pos, pc.T)\n",
    "        activation_neg_projected = np.dot(activations_neg, pc.T)\n",
    "        for i, (x,y) in enumerate(activation_pos_projected):\n",
    "            if letters_pos[i] == ans1:\n",
    "                ax.scatter(x, y, color=\"blue\", marker=\"o\")\n",
    "            elif letters_pos[i] == ans2:\n",
    "                ax.scatter(x, y, color=\"blue\", marker=\"x\")\n",
    "        for i, (x,y) in enumerate(activation_neg_projected):\n",
    "            if letters_neg[i] == ans1:\n",
    "                ax.scatter(x, y, color=\"red\", marker=\"o\")\n",
    "            elif letters_neg[i] == ans2:\n",
    "                ax.scatter(x, y, color=\"red\", marker=\"x\")\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xtitle('PC1' if \"pc2\" not in type else 'PC2')\n",
    "        if type==\"both\":\n",
    "            ax.legend(handles=[\n",
    "                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label=f\"Pos {behavior} - {ans1}\"),\n",
    "                plt.Line2D([0], [0], marker='x', color='blue', markerfacecolor='blue', markersize=10, label=f\"Pos {behavior} - {ans2}\"),\n",
    "                plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label=f\"Neg {behavior} - {ans1}\"),\n",
    "                plt.Line2D([0], [0], marker='x', color='red', markerfacecolor='red', markersize=10, label=f\"Neg {behavior} - {ans2}\")\n",
    "            ])\n",
    "        else:\n",
    "            ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 17\n",
    "position=0\n",
    "pcatype = \"raw\"\n",
    "behavior=\"Honesty\"\n",
    "\n",
    "activations_pos = accumulated_activations_pos[layer][position]\n",
    "activations_neg = accumulated_activations_neg[layer][position]\n",
    "\n",
    "if pcatype == \"raw\":\n",
    "    activations = torch.cat([activations_pos, activations_neg], dim=0)\n",
    "    pca_input = activations - activations.mean(axis=0, keepdims=True)\n",
    "else:\n",
    "    pca_input = accumulated_activations_diff[layer][pos] - accumulated_activations_diff[layer][pos].mean(axis=0, keepdim=True)\n",
    "\n",
    "pca_model = PCA(n_components=2, whiten=False).fit(pca_input)\n",
    "pc1 = pca_model.components_[0] \n",
    "pc2 = pca_model.components_[1] \n",
    "fig, axes = plt.subplots(5, 3, figsize=(18, 24))\n",
    "\n",
    "plot_projection(torch.cat([activations_pos[letters_pos == ans1],activations_neg[letters_neg == ans2]], dim=0), torch.cat([activations_neg[letters_neg == ans1],activations_pos[letters_pos == ans2]], dim=0), pc1, axes[0,1], 'Projection of Statements on PC1 (fact detector)', type=\"pc1_Truth\")\n",
    "plot_projection(activations_pos[letters_pos == ans1], activations_neg[letters_neg == ans1], pc1, axes[0,2], 'Projection of Statements Labeled True on PC1 (fact detector)', type=\"pc1_Truth\")\n",
    "plot_projection(activations_neg[letters_neg == ans2], activations_pos[letters_pos == ans2], pc1, axes[1,0], 'Projection of Statements Labeled False on PC1 (fact detector)', type=\"pc1_Truth\")\n",
    "plot_projection(torch.cat([activations_pos[letters_pos == ans1],activations_neg[letters_neg == ans2]], dim=0), torch.cat([activations_neg[letters_neg == ans1],activations_pos[letters_pos == ans2]], dim=0), pc2, axes[1,1], 'Projection of Statements on PC2 (fact detector)', type=\"pc2_Truth\")\n",
    "plot_projection(activations_pos[letters_pos == ans1], activations_neg[letters_neg == ans1], pc2, axes[1,2], 'Projection of Statements Labeled True on PC2 (fact detector)', type=\"pc2_Truth\")\n",
    "plot_projection(activations_neg[letters_neg == ans2], activations_pos[letters_pos == ans2], pc2, axes[2,0], 'Projection of Statements Labeled False on PC2 (fact detector)', type=\"pc2_Truth\")\n",
    "plot_projection(torch.cat([activations_pos[letters_pos == ans1],activations_pos[letters_pos == ans2]], dim=0), torch.cat([activations_neg[letters_neg == ans1],activations_neg[letters_neg == ans2]], dim=0), pc1, axes[2,1], 'Projection of Statements on PC1 (lie detector)', type=\"pc1_Honesty\")\n",
    "plot_projection(activations_pos[letters_pos == ans1], activations_neg[letters_neg == ans2], pc1, axes[2,2], 'Projection of True Statements on PC1 (lie detector)', type=\"pc1_Honesty\")\n",
    "plot_projection(activations_pos[letters_pos == ans2], activations_neg[letters_neg == ans1], pc1, axes[3,0], 'Projection of False Statements on PC1 (lie detector)', type=\"pc1_Honesty\")\n",
    "plot_projection(torch.cat([activations_pos[letters_pos == ans1],activations_pos[letters_pos == ans2]], dim=0), torch.cat([activations_neg[letters_neg == ans1],activations_neg[letters_neg == ans2]], dim=0), pc2, axes[3,1], 'Projection of Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "plot_projection(activations_pos[letters_pos == ans1], activations_neg[letters_neg == ans2], pc2, axes[3,2], 'Projection of True Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "plot_projection(activations_pos[letters_pos == ans2], activations_neg[letters_neg == ans1], pc2, axes[4,0], 'Projection of False Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(pca_model.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(range(9,model_numlayers))\n",
    "position=0\n",
    "fig, axes = plt.subplots(len(layers), 3, figsize=(18, len(layers)*5))\n",
    "for i, layer in enumerate(layers):\n",
    "    activation_pos = accumulated_activations_pos[layer][position]\n",
    "    activation_neg = accumulated_activations_neg[layer][position]\n",
    "\n",
    "    pc2 = enhanced_hook_activation_to_add[layer][position]\n",
    "\n",
    "    plot_projection(torch.cat([activations_pos[letters_pos == ans1],activations_pos[letters_pos == ans2]], dim=0), torch.cat([activations_neg[letters_neg == ans1],activations_neg[letters_neg == ans2]], dim=0), pc2, axes[i,0], f'Layer {layer} Projection of Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "    plot_projection(activations_pos[letters_pos == ans1], activations_neg[letters_neg == ans2], pc2, axes[i,1], f'Layer {layer} Projection of True Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "    plot_projection(activations_pos[letters_pos == ans2], activations_neg[letters_neg == ans1], pc2, axes[i,2], f'Layer {layer} Projection of False Statements on PC2 (lie detector)', type=\"pc2_Honesty\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datadir+\"gpt4_facts.csv\") #eval\n",
    "\n",
    "def template_test(suffix: str) -> str:\n",
    "    return f\"{user_tag}Question: Is the following claim true or false? {suffix}\\n\\nChoices:\\n (A) True\\n (B) False\\n\\nAnswer:{asst_tag}\"\n",
    "\n",
    "prompts_to_be_steered = []\n",
    "for statement in df['statement']:\n",
    "    prompts_to_be_steered.append(template_test(statement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa_gen_ds = load_dataset('truthful_qa', 'generation')['validation'].filter(lambda example: 'Mis' in example['category'])\n",
    "def template(q: str, a_resp: str, b_resp:str) -> str:\n",
    "    return f\"{user_tag}Question: {q} \\n\\nChoices:\\n(A) {a_resp}\\n (B) {b_resp}\\n\\nAnswer:{asst_tag}\"\n",
    "\n",
    "prompts_to_be_steered_tqa = []\n",
    "for i in range(5, len(tqa_gen_ds)):\n",
    "    if i%2: prompts_to_be_steered_tqa.append(template(tqa_gen_ds[i]['question'], tqa_gen_ds[i]['best_answer'], tqa_gen_ds[i]['incorrect_answer'][0]))\n",
    "    else: prompts_to_be_steered_tqa.append(template(tqa_gen_ds[i]['question'], tqa_gen_ds[i]['incorrect_answer'][0], tqa_gen_ds[i]['best_answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enhanced_hooking import zeroout_projections_and_generate\n",
    "sampling_kwargs = {\"use_cache\": True#false\n",
    "                   ,\"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 30, \"do_sample\": False, \"repetition_penalty\": 1.1\n",
    "                    #, \"temperature\": 0.5\n",
    "                   #, \"top_p\": 0.3\n",
    "                   #,\"penalty_alpha\": 0.6 \n",
    "                   #,\"top_k\": 4\n",
    "                   }\n",
    "fname = \"continuoussteer_nonorm_gpt4facts_pca2diff_zeroout_llama2-7b\"\n",
    "main_file_path = outputdir+fname+\".json\"\n",
    "tmp_file_path = outputdir+fname+\"_tmp.json\"\n",
    "results = []\n",
    "layersets = [[layer] for layer in [17, 18, 19, 31, 17, 31]]\n",
    "mults=[4,6,8,10,12,14,16]\n",
    "\n",
    "batched_inputs = [\n",
    "    prompts_to_be_steered[p:p+batch_size] for p in range(0, len(prompts_to_be_steered), batch_size)\n",
    "]\n",
    "model.tokenizer.padding_side = \"left\"\n",
    "clear_hooks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_batch_decode(generated_tokens, input_ids, tokenizer):\n",
    "    batch_size = generated_tokens.shape[0]\n",
    "    start_indices = input_ids.shape[1]\n",
    "    max_len = generated_tokens.shape[1] - start_indices\n",
    "    tokens_to_decode = torch.full((batch_size, max_len), tokenizer.pad_token_id, dtype=torch.long)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        len_to_decode = generated_tokens.shape[1] - input_ids.shape[1]\n",
    "        tokens_to_decode[i, :len_to_decode] = generated_tokens[i, input_ids.shape[1]:]\n",
    "    return tokenizer.batch_decode(tokens_to_decode, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in batched_inputs:\n",
    "    model.to(device)\n",
    "    inputs = model.tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "    generated_tokens = model.generate(**inputs, **sampling_kwargs)\n",
    "    original_output = do_batch_decode(generated_tokens, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "    steered_entries = {}\n",
    "    for mult in mults:\n",
    "        for layerlist in layersets:\n",
    "            layer_activations = {}\n",
    "            continuous_layer_activations = {}\n",
    "            for layer in layerlist:\n",
    "                continuous_layer_activations[layer] = (enhanced_hook_activation_to_add[layer][-1] * mult).to(device)\n",
    "            \n",
    "            genereated_tokens = add_activations_and_generate(model, inputs, layer_activations, continuous_layer_activations, sampling_kwargs, add_at=add_at)\n",
    "            enhanced_hook_steered_output_pos = do_batch_decode(generated_tokens, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "            if mult == mults[0]:\n",
    "                generated_tokens = zeroout_projections_and_generate(model, inputs, {layer: enhanced_hook_activation_to_add[layer][-1].to(device) for layer in layerlist}, sampling_kwargs)\n",
    "                enhanced_hook_zeroedout_output_pos = do_batch_decode(generated_tokens, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "            for k, v in layer_activations.items():\n",
    "                for pos_k, pos_v in v.items():\n",
    "                    layer_activations[k][pos_k] = -pos_v\n",
    "            for k, v in continuous_layer_activations:\n",
    "                continuous_layer_activations[k] = -v\n",
    "            \n",
    "            genereated_tokens = add_activations_and_generate(model, inputs, layer_activations, continuous_layer_activations, sampling_kwargs, add_at=add_at)\n",
    "            enhanced_hook_steered_output_neg = do_batch_decode(generated_tokens, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "            if mult == mults[0]: #will be the same across multipliers\n",
    "                generated_tokens = zeroout_projections_and_generate(model, inputs, {layer: (enhanced_hook_activation_to_add[layer][-1] * -1).to(device) for layer in layerlist}, sampling_kwargs)\n",
    "                enhanced_hook_zeroedout_output_neg = do_batch_decode(generated_tokens, inputs['input_ids'], model.tokenizer)\n",
    "\n",
    "            steered_entries[f\"layer{','.join([str(layer) for layer in layerlist])}_mult{mult}\"] = {\n",
    "                \"answer_zeroedout_pos\": enhanced_hook_zeroedout_output_pos,\n",
    "                \"answer_zeroedout_neg\": enhanced_hook_zeroedout_output_neg,\n",
    "                \"answer_pos\": enhanced_hook_steered_output_pos,\n",
    "                \"answer_neg\": enhanced_hook_steered_output_neg\n",
    "            }\n",
    "    for i in range(len(batch)):\n",
    "        current_prompt = batch[i]\n",
    "        current_original_output = original_output[i]\n",
    "        current_steered_entries = {}\n",
    "        for category, keys_values in steered_entries.items():#awkward processing due to the nested structure of steered_entries, but will leave for now\n",
    "            current_category = {}\n",
    "            for key, value_list in keys_values.items():\n",
    "                current_category[key] = value_list[i] \n",
    "            current_steered_entries[category] = current_category\n",
    "        results.append({\n",
    "            \"sentence\": current_prompt,\n",
    "            \"answer_neut\": current_original_output,\n",
    "            \"steered\": current_steered_entries\n",
    "        }) \n",
    "    \n",
    "    print(f\"Finished sentence {len(results)}\")\n",
    "\n",
    "    try:\n",
    "        with open(tmp_file_path, \"w\") as rfile:\n",
    "            json.dump(results, rfile)\n",
    "        os.replace(tmp_file_path, main_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to write data: {str(e)}\")\n",
    "\n",
    "    print(f\"Input: {batch}\")\n",
    "    print(f\"Original Output: {original_output}\")\n",
    "    print(f\"Pos output: {enhanced_hook_steered_output_pos}\")\n",
    "    print(f\"Neg output: {enhanced_hook_steered_output_neg}\")\n",
    "    print(f\"Zeroedout Pos output: {enhanced_hook_zeroedout_output_pos}\")\n",
    "    print(f\"Zeroedout Neg output: {enhanced_hook_zeroedout_output_neg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_vectors = {} #dictionary where keys are layers and values are lists of n_pos direction tensors\n",
    "for layer, positions in accumulated_activations_diff.items():#dictionary where keys are layers and values are dicts where keys are positions and values are len(dataset) d-embed tensors\n",
    "    embeds = []\n",
    "    for pos in range(len(positions)):\n",
    "        train = positions[pos] - positions[pos].mean(axis=0, keepdims=True)\n",
    "        pca_model = PCA(n_components=2, whiten=False).fit(train)\n",
    "        coef1, coef2 = 1,0#pca_model.explained_variance_[0],pca_model.explained_variance_[1]\n",
    "        embeds.append(torch.from_numpy(pca_model.components_[0].astype(np.float32))*coef1/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[0].astype(np.float32))))\n",
    "        embeds[-1]+=torch.from_numpy(pca_model.components_[1].astype(np.float32))*coef2/(coef1+coef2)*get_sign(accumulated_activations_pos[layer][pos],accumulated_activations_neg[layer][pos],torch.from_numpy(pca_model.components_[1].astype(np.float32)))\n",
    "    fact_vectors[layer] = torch.stack(embeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 19\n",
    "model.tokenizer.padding_side= \"left\"\n",
    "sampling_kwargs={\"use_cache\": True, \"pad_token_id\": model.tokenizer.eos_token_id, \"max_new_tokens\": 2}\n",
    "directions = {layer: posvec[-1] for layer, posvec in fact_vectors.items()} #directions = {layer: posvec[-1] for layer, posvec in steering_vectors.items()}\n",
    "inputdata = [x for x, y in dataset[:len(dataset)//2]] + [y for x, y in dataset[len(dataset)//2:]] + [y for x, y in dataset[:len(dataset)//2]] + [x for x, y in dataset[len(dataset)//2:]] #first half true facts, second half false facts\n",
    "#inputdata = [prompts_to_be_steered_tqa[i] for i in range(0,len(prompts_to_be_steered_tqa),2)] + [prompts_to_be_steered_tqa[i] for i in range(1,len(prompts_to_be_steered_tqa),2)]\n",
    "#inputdata = [prompts_to_be_steered[i] for j in range(0, len(prompts_to_be_steered)//10 , 2) for i in range(j*10, j*10+10)] + [prompts_to_be_steered[i] for j in range(1, len(prompts_to_be_steered)//10 , 2) for i in range(j*10, j*10+10)]\n",
    "\n",
    "accumulated_projections = defaultdict(lambda: defaultdict(lambda: torch.empty(0)))\n",
    "batched_inputs = [\n",
    "        inputdata[p : p + batch_size]\n",
    "        for p in range(0, len(inputdata), batch_size)\n",
    "]\n",
    "clear_hooks(model)\n",
    "model.to(device)\n",
    "for batch in tqdm(batched_inputs, desc='Generating projections'):\n",
    "    inputs = model.tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    get_at = add_at = \"end\"\n",
    "\n",
    "    layers_positions = {}\n",
    "    for layer in layers:\n",
    "        layers_positions[layer] = [[len(inputs['input_ids'][pos])-offset for offset in range(lookback,0,-1)] for pos in range(len(inputs['input_ids']))]\n",
    "\n",
    "    activations = get_activations_and_generate(model, inputs, layers_positions, sampling_kwargs, get_at=get_at) #returns a dictionary where keys are layers and values are dicts where keys are positions and values are batchsize d-embed tensors\n",
    "    for layer, positions in activations.items():\n",
    "        for pos, tensor in positions.items():#each of these is a stack of batchsize d-embed tensors for a given position\n",
    "            projection = (tensor @ directions[layer].to(tensor.dtype)) / (torch.norm(directions[layer]) * torch.norm(tensor, dim=1))\n",
    "            accumulated_projections[layer][pos] = torch.cat([accumulated_projections[layer][pos], projection], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = list(range(len(accumulated_projections)))\n",
    "positions = range(len(accumulated_projections[0]))\n",
    "offset = lookback\n",
    "split=len(accumulated_projections[0][0]) // 2\n",
    "data = np.zeros((len(layers), len(positions)))\n",
    "honest_mean_data = np.zeros((len(layers), len(positions)))\n",
    "dishonest_mean_data = np.zeros((len(layers), len(position)))\n",
    "\n",
    "for i, layer in enumerate(layers):\n",
    "    for j, position in enumerate(positions):\n",
    "        honest_mean_data[i,j] = torch.mean(accumulated_projections[layer][position][:split]).item()\n",
    "        dishonest_mean_data[i,j] = torch.mean(accumulated_projections[layer][position][split:]).item()\n",
    "        data[i,j] = honest_mean_data[i,j] - dishonest_mean_data[i,j]\n",
    "\n",
    "data_flipped = data[::-1, :]\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "\n",
    "\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_flipped, xticklabels=[p - offset for p in positions], yticklabels=sorted(layers,reverse=True), annot=False, cmap='coolwarm', vmin=-rmabs, vmax=rmabs)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Honesty Projections')\n",
    "plt.show()\n",
    "\n",
    "data_flipped = dishonest_mean_data[::-1, :] # Flip to show first layer at bottom\n",
    "\n",
    "max_abs_value = np.max(np.abs(data_flipped))\n",
    "rmabs = round(max_abs_value, -int(np.floor(np.log10(max_abs_value))))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_flipped, xticklabels=[p - offset for p in positions], yticklabels=sorted(layers,reverse=True), annot=False, cmap='coolwarm', vmin=-rmabs, vmax=rmabs)\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Layer')\n",
    "plt.title('Dishonesty Projections')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 0\n",
    "top_k = 10\n",
    "mult = 20\n",
    "colorscale = \"Reds\" if mult>=0 else \"Blues\"\n",
    "\n",
    "token_data = []\n",
    "probs_data = []\n",
    "\n",
    "for layer in range(model_numlayers):\n",
    "    vec = (mult*steering_vectors[layer][position]).to(device)\n",
    "    unembedded = model.lm_head(model.model.norm(vec.to(model.dtype)))\n",
    "    softmaxed = torch.nn.functional.softmax(unembedded, dim=-1)\n",
    "    values, indicies = torch.topk(softmaxed, top_k)\n",
    "    probs_precent = [v for v in values.tolist()]\n",
    "    tokens = model.tokenizer.batch_decode(indicies.unsqueeze(-1))\n",
    "    token_data.append(tokens)\n",
    "    probs_data.append(probs_precent)\n",
    "\n",
    "probs_array = np.array(probs_data)\n",
    "token_labels = np.array(token_data)\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans' \n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.heatmap(probs_array, annot=token_labels, fmt='', cmap=colorscale, xticklabels=False, yticklabels=[f\"Layer {l}\" for l in range(model_numlayers)])\n",
    "ax.set_title(f\"Logit Lens Top Token Probabilities at Multiplier {mult}\")\n",
    "ax.set_xlabel(f\"Top {top_k} Tokens\")\n",
    "\n",
    "# Adding a highlight for specific layers\n",
    "for layerlist in [[17,18]]:\n",
    "    rect = patches.Rectangle((0, layerlist[0]), top_k, len(layerlist), linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
